{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Estimating the epistemic uncertainty in SMLM microscopy image classification\n",
        "In this notebook we will be estimating the epistemic uncertainty in SMLM microscopy classification using Monte Carlo Dropout. The table of contents is the following:\n",
        "- INSERT TOC"
      ],
      "metadata": {
        "id": "PlZSSNIGYzet"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "nVGZjma9Z0o0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tifffile\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "hLdNWn5ZfDUo"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing raw data"
      ],
      "metadata": {
        "id": "7HZKpc_BZ8gk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KF4ZXIbSBjW",
        "outputId": "ea14f70f-c252-449d-83b7-808ddcf372a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5040, 128, 128)\n",
            "(5040,)\n",
            "[0 1 2 3 4 5 6]\n"
          ]
        }
      ],
      "source": [
        "name2label = {'7art': 0, '7ary': 1, '7as5': 2, '7bho': 3, 'hemisphere': 4, 'icosahedron': 5, 'tetrahedron': 6} # Dictionary and mapping used for encoding class names to labels\n",
        "vectorized_map = np.vectorize(name2label.get)\n",
        "\n",
        "def load_train_SMLM(train_path):\n",
        "  X_trainval_SMLM = []\n",
        "  y_trainval_SMLM = []\n",
        "\n",
        "  for class_folder in os.listdir(train_path):\n",
        "      tif_file_train = os.path.join(train_path, class_folder)\n",
        "      class_name = os.path.basename(tif_file_train)[:-4]\n",
        "\n",
        "      if class_name[-4:] == 'SMLM':\n",
        "        SMLM_image_data = tifffile.imread(tif_file_train)\n",
        "        tif_file_size = len(SMLM_image_data)\n",
        "\n",
        "        X_trainval_SMLM.append(SMLM_image_data)\n",
        "        y_trainval_SMLM += tif_file_size * [class_name[:-5]]\n",
        "\n",
        "      elif class_name[-2:] == 'EM':\n",
        "        continue\n",
        "\n",
        "      else:\n",
        "        raise ValueError('Image must be SMLM image.')\n",
        "\n",
        "  X_trainval_SMLM = np.concatenate(X_trainval_SMLM, axis=0)\n",
        "  y_trainval_SMLM = np.array(y_trainval_SMLM)\n",
        "\n",
        "  y_trainval_SMLM = vectorized_map(y_trainval_SMLM)\n",
        "\n",
        "  return X_trainval_SMLM, y_trainval_SMLM\n",
        "\n",
        "train_path = '/content/drive/MyDrive/FAIP_2022_data/train'\n",
        "X_trainval_SMLM, y_trainval_SMLM = load_train_SMLM(train_path)\n",
        "\n",
        "print(X_trainval_SMLM.shape)\n",
        "print(y_trainval_SMLM.shape)\n",
        "print(np.unique(y_trainval_SMLM))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_test_SMLM(test_path):\n",
        "  X_test_SMLM = []\n",
        "  y_test_SMLM = []\n",
        "\n",
        "  for class_folder in os.listdir(test_path):\n",
        "      tif_file_test = os.path.join(test_path, class_folder)\n",
        "      class_name = os.path.basename(tif_file_test)[:-4]\n",
        "\n",
        "      if class_name[-4:] == 'SMLM':\n",
        "        SMLM_image_data = tifffile.imread(tif_file_test)\n",
        "        tif_file_size = len(SMLM_image_data)\n",
        "\n",
        "        X_test_SMLM.append(SMLM_image_data)\n",
        "        y_test_SMLM += tif_file_size * [class_name[:-5]]\n",
        "\n",
        "      elif class_name[-2:] == 'EM':\n",
        "        continue\n",
        "\n",
        "      else:\n",
        "        raise ValueError('Image must be SMLM image.')\n",
        "\n",
        "  X_test_SMLM = np.concatenate(X_test_SMLM, axis=0)\n",
        "  y_test_SMLM = np.array(y_test_SMLM)\n",
        "\n",
        "  y_test_SMLM = vectorized_map(y_test_SMLM)\n",
        "\n",
        "  return X_test_SMLM, y_test_SMLM\n",
        "\n",
        "test_path = '/content/drive/MyDrive/FAIP_2022_data/test'\n",
        "X_test_SMLM, y_test_SMLM = load_test_SMLM(test_path)\n",
        "\n",
        "print(X_test_SMLM.shape)\n",
        "print(y_test_SMLM.shape)\n",
        "print(np.unique(y_test_SMLM))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3pyWuvLUrN2",
        "outputId": "25898360-de1b-4eae-9a59-d0989a822e41"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1260, 128, 128)\n",
            "(1260,)\n",
            "[0 1 2 3 4 5 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yTek5HMTnUYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_SMLM, X_val_SMLM, y_train_SMLM, y_val_SMLM = train_test_split(X_trainval_SMLM, y_trainval_SMLM, test_size=0.25, random_state=42)\n",
        "print(X_train_SMLM.shape)\n",
        "print(X_val_SMLM.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOm8D-OKnT9N",
        "outputId": "ed8315d7-8c1c-4867-a5a0-a4bc7de42171"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3780, 128, 128)\n",
            "(1260, 128, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SMLMDataset class and creating dataloaders"
      ],
      "metadata": {
        "id": "2xhMrVaWfp2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate mean\n",
        "mean = np.mean(X_train_SMLM, axis=(1, 2)) # This computes the mean for each image\n",
        "overall_mean = np.mean(mean) # This computes the overall mean across all images\n",
        "\n",
        "# Calculate standard deviation\n",
        "std_dev = np.std(X_train_SMLM, axis=(1, 2)) # This computes the standard deviation for each image\n",
        "overall_std_dev = np.mean(std_dev) # This computes the overall standard deviation across all images\n",
        "\n",
        "print(\"Mean:\", overall_mean)\n",
        "print(\"Standard Deviation:\", overall_std_dev)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OzQjXuSi0vd",
        "outputId": "4d099053-03a6-4a2f-9a8d-207dcbc67e4e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: 0.6123785755621693\n",
            "Standard Deviation: 2.2223346004114672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "class SMLMDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    # transforms.Resize((64, 64)), # Resizing image\n",
        "    transforms.ToTensor(), # Converting to Tensor\n",
        "    transforms.Normalize((0.61237,), (2.22233,)) # Normalizing pixels\n",
        "])\n",
        "\n",
        "train_dataset_SMLM = SMLMDataset(X_train_SMLM, y_train_SMLM, transform=transform)\n",
        "val_dataset_SMLM = SMLMDataset(X_val_SMLM, y_val_SMLM, transform=transform)\n",
        "test_dataset_SMLM = SMLMDataset(X_val_SMLM, y_val_SMLM, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset_SMLM, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset_SMLM, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset_SMLM, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "S_6lCju8fnhR"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network Classes"
      ],
      "metadata": {
        "id": "6tEicFNlpnXS"
      }
    }
  ]
}